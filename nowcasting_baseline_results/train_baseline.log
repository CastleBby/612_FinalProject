epoch,train_loss,val_loss,lr
1,0.162109,0.401945,0.00009998
2,0.158119,0.396040,0.00009990
3,0.157728,0.404996,0.00009978
4,0.157111,0.405252,0.00009961
5,0.156810,0.397126,0.00009938
6,0.156616,0.397323,0.00009911
7,0.156538,0.393656,0.00009880
8,0.155996,0.393948,0.00009843
9,0.155758,0.394174,0.00009801
10,0.155537,0.392542,0.00009755
11,0.155666,0.395185,0.00009704
12,0.155709,0.392062,0.00009649
13,0.155469,0.394406,0.00009589
14,0.155103,0.395161,0.00009524
15,0.155024,0.397275,0.00009455
16,0.154803,0.392126,0.00009382
17,0.154356,0.394798,0.00009304
18,0.154786,0.396293,0.00009222
19,0.154114,0.393870,0.00009135
20,0.154555,0.398913,0.00009045
21,0.154425,0.395260,0.00008951
22,0.154295,0.395150,0.00008853
23,0.153680,0.403447,0.00008751
24,0.153985,0.394604,0.00008645
25,0.153598,0.394601,0.00008536
26,0.153733,0.394145,0.00008423
27,0.153511,0.400875,0.00008307
